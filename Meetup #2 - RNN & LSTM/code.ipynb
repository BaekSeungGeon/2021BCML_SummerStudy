{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hungarian-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy와 copy를 import 하고 random 값의 seed를 심는다\n",
    "# copy는 object를 복제하는데 쓰인다 https://pymotw.com/2/copy/\n",
    "import copy, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pointed-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility 함수들 구현\n",
    "# 시그모이드 함수 구현\n",
    "def sigmoid(x):\n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "# 시그모이드 함수의 미분\n",
    "# http://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output * (1 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dominant-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set을 위한 lookup table을 만든다. dictionary로 1:00000001 이런 식으로 미리 만들어두는 것\n",
    "int2binary = {}  # lookup table 이다.\n",
    "binary_dim = 8  # 이진수는 최대 8자리. 이걸 넘어가진 않는다고 제한해두자.\n",
    "largest_number = pow(2, binary_dim)  # 따라서 최대값은 2^8 -1 이 되겠지? 1 0000 0000 - 1 = 1111 1111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "terminal-illness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 1]\n",
      "====================\n",
      "1. Just range()\n",
      "(256,) [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255]\n",
      "2. 2-d list\n",
      "(1, 256) [[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      "  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      "  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      "  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      "  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      "  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      "  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      "  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      "  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      "  252 253 254 255]]\n",
      "transpose\n",
      "(256, 1) [[  0]\n",
      " [  1]\n",
      " [  2]\n",
      " [  3]\n",
      " [  4]\n",
      " [  5]\n",
      " [  6]\n",
      " [  7]\n",
      " [  8]\n",
      " [  9]\n",
      " [ 10]\n",
      " [ 11]\n",
      " [ 12]\n",
      " [ 13]\n",
      " [ 14]\n",
      " [ 15]\n",
      " [ 16]\n",
      " [ 17]\n",
      " [ 18]\n",
      " [ 19]\n",
      " [ 20]\n",
      " [ 21]\n",
      " [ 22]\n",
      " [ 23]\n",
      " [ 24]\n",
      " [ 25]\n",
      " [ 26]\n",
      " [ 27]\n",
      " [ 28]\n",
      " [ 29]\n",
      " [ 30]\n",
      " [ 31]\n",
      " [ 32]\n",
      " [ 33]\n",
      " [ 34]\n",
      " [ 35]\n",
      " [ 36]\n",
      " [ 37]\n",
      " [ 38]\n",
      " [ 39]\n",
      " [ 40]\n",
      " [ 41]\n",
      " [ 42]\n",
      " [ 43]\n",
      " [ 44]\n",
      " [ 45]\n",
      " [ 46]\n",
      " [ 47]\n",
      " [ 48]\n",
      " [ 49]\n",
      " [ 50]\n",
      " [ 51]\n",
      " [ 52]\n",
      " [ 53]\n",
      " [ 54]\n",
      " [ 55]\n",
      " [ 56]\n",
      " [ 57]\n",
      " [ 58]\n",
      " [ 59]\n",
      " [ 60]\n",
      " [ 61]\n",
      " [ 62]\n",
      " [ 63]\n",
      " [ 64]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 67]\n",
      " [ 68]\n",
      " [ 69]\n",
      " [ 70]\n",
      " [ 71]\n",
      " [ 72]\n",
      " [ 73]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 83]\n",
      " [ 84]\n",
      " [ 85]\n",
      " [ 86]\n",
      " [ 87]\n",
      " [ 88]\n",
      " [ 89]\n",
      " [ 90]\n",
      " [ 91]\n",
      " [ 92]\n",
      " [ 93]\n",
      " [ 94]\n",
      " [ 95]\n",
      " [ 96]\n",
      " [ 97]\n",
      " [ 98]\n",
      " [ 99]\n",
      " [100]\n",
      " [101]\n",
      " [102]\n",
      " [103]\n",
      " [104]\n",
      " [105]\n",
      " [106]\n",
      " [107]\n",
      " [108]\n",
      " [109]\n",
      " [110]\n",
      " [111]\n",
      " [112]\n",
      " [113]\n",
      " [114]\n",
      " [115]\n",
      " [116]\n",
      " [117]\n",
      " [118]\n",
      " [119]\n",
      " [120]\n",
      " [121]\n",
      " [122]\n",
      " [123]\n",
      " [124]\n",
      " [125]\n",
      " [126]\n",
      " [127]\n",
      " [128]\n",
      " [129]\n",
      " [130]\n",
      " [131]\n",
      " [132]\n",
      " [133]\n",
      " [134]\n",
      " [135]\n",
      " [136]\n",
      " [137]\n",
      " [138]\n",
      " [139]\n",
      " [140]\n",
      " [141]\n",
      " [142]\n",
      " [143]\n",
      " [144]\n",
      " [145]\n",
      " [146]\n",
      " [147]\n",
      " [148]\n",
      " [149]\n",
      " [150]\n",
      " [151]\n",
      " [152]\n",
      " [153]\n",
      " [154]\n",
      " [155]\n",
      " [156]\n",
      " [157]\n",
      " [158]\n",
      " [159]\n",
      " [160]\n",
      " [161]\n",
      " [162]\n",
      " [163]\n",
      " [164]\n",
      " [165]\n",
      " [166]\n",
      " [167]\n",
      " [168]\n",
      " [169]\n",
      " [170]\n",
      " [171]\n",
      " [172]\n",
      " [173]\n",
      " [174]\n",
      " [175]\n",
      " [176]\n",
      " [177]\n",
      " [178]\n",
      " [179]\n",
      " [180]\n",
      " [181]\n",
      " [182]\n",
      " [183]\n",
      " [184]\n",
      " [185]\n",
      " [186]\n",
      " [187]\n",
      " [188]\n",
      " [189]\n",
      " [190]\n",
      " [191]\n",
      " [192]\n",
      " [193]\n",
      " [194]\n",
      " [195]\n",
      " [196]\n",
      " [197]\n",
      " [198]\n",
      " [199]\n",
      " [200]\n",
      " [201]\n",
      " [202]\n",
      " [203]\n",
      " [204]\n",
      " [205]\n",
      " [206]\n",
      " [207]\n",
      " [208]\n",
      " [209]\n",
      " [210]\n",
      " [211]\n",
      " [212]\n",
      " [213]\n",
      " [214]\n",
      " [215]\n",
      " [216]\n",
      " [217]\n",
      " [218]\n",
      " [219]\n",
      " [220]\n",
      " [221]\n",
      " [222]\n",
      " [223]\n",
      " [224]\n",
      " [225]\n",
      " [226]\n",
      " [227]\n",
      " [228]\n",
      " [229]\n",
      " [230]\n",
      " [231]\n",
      " [232]\n",
      " [233]\n",
      " [234]\n",
      " [235]\n",
      " [236]\n",
      " [237]\n",
      " [238]\n",
      " [239]\n",
      " [240]\n",
      " [241]\n",
      " [242]\n",
      " [243]\n",
      " [244]\n",
      " [245]\n",
      " [246]\n",
      " [247]\n",
      " [248]\n",
      " [249]\n",
      " [250]\n",
      " [251]\n",
      " [252]\n",
      " [253]\n",
      " [254]\n",
      " [255]]\n",
      "np.unpackbits\n",
      "(256, 8) [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [1 1 1 ... 1 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "{}\n",
      "[0 0 0 0 0 0 1 1]\n",
      "[0 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Create binary lookup table\n",
    "# numpy.unpackbits 테스트\n",
    "print(np.unpackbits(np.array([3], dtype=np.uint8)))\n",
    "print(\"====================\")\n",
    "\n",
    "# 0 부터 우리가 다룰 최대값(largest_number-1)까지의 숫자를 2진수의 리스트로 변환해두자\n",
    "# 눈으로 알아보기 쉽게 단계별로 본다\n",
    "\n",
    "# range만 해도 리스트를 만든다\n",
    "binary = np.array(range(largest_number), dtype = np.uint8)\n",
    "print(\"1. Just range()\")\n",
    "print(binary.shape, binary)\n",
    "\n",
    "# range만 해도 리스트를 만드는데 다시 []를 먹였으니 리스트가 2개인게 보인다.\n",
    "binary = np.array([range(largest_number)], dtype = np.uint8)\n",
    "print(\"2. 2-d list\")\n",
    "print(binary.shape, binary)\n",
    "\n",
    "# 이걸 transpose 해준다. \n",
    "binary = binary.T\n",
    "print('transpose')\n",
    "print(binary.shape, binary)\n",
    "\n",
    "# 마지막으로 np.unpackbits 를 먹인다. \n",
    "print('np.unpackbits')\n",
    "binary = np.unpackbits(np.array([range(largest_number)], dtype = np.uint8).T, axis=1)\n",
    "print(binary.shape, binary)\n",
    "\n",
    "print(int2binary)  # 초기에는 아무것도 없는 딕셔너리\n",
    "print(binary[3])\n",
    "\n",
    "# 값을 채우고\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "\n",
    "print(int2binary[3]) # 테스트 삼아 출력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outside-subject",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16) (16, 1) (16, 16)\n"
     ]
    }
   ],
   "source": [
    "# Initial parameter setting\n",
    "\n",
    "alpha = 0.1 # learning_rate\n",
    "input_node_num = 2 # 우리는 이진수 두 개의 같은 자리 값을 입력으로 넣는다\n",
    "\n",
    "# hidden 계층의 노드는 16개로 하였다. 이것이 carry 정보를 저장할 것이다. \n",
    "# 현재 8자리의 이진수를 다루니 hidden 계층이 16개면 충분할듯 하다. 이 값을 변경해가며 \n",
    "# 얼마나 빨리 최종값을 찾아가는지 테스트 해보자\n",
    "\n",
    "hidden_node_num = 16\n",
    "output_node_num = 1  # 각 자리수의 결과값이 여기에 온다\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# initialize neural network weights\n",
    "# weight 값들을 정해 준다. \n",
    "# [0.0, 1.0) 사이의 랜덤으로 만든 값들에 2를 곱해주고 1을 빼준다. 따라서 [-1, 1.0) 값이 생성된다. \n",
    "# http://terms.naver.com/entry.nhn?docId=3404970&cid=47324&categoryId=47324\n",
    "# np.random.random은 [0,0, 1.0) 의 값을 생성해준다. half open interval 이라 하는데 간단히 0.0 <= y < 1.0 이다.\n",
    "# 값들을 여러개 생성하면 continueous uniform하게 만들어준다.\n",
    "w0 = 2 * np.random.random((input_node_num, hidden_node_num)) - 1\n",
    "w1 = 2 * np.random.random((hidden_node_num, output_node_num)) - 1\n",
    "wh = 2 * np.random.random((hidden_node_num, hidden_node_num)) - 1\n",
    "\n",
    "print (w0.shape, w1.shape, wh.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "filled-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wieght를 업데이트 하기 위한 용도의 공간도 잡아둔다. shape는 똑같겠지?\n",
    "w0_update = np.zeros_like(w0)\n",
    "w1_update = np.zeros_like(w1)\n",
    "wh_update = np.zeros_like(wh)\n",
    "\n",
    "# display 용도\n",
    "overallError_history = list()\n",
    "accuracy = list()\n",
    "accuracy_history = list()\n",
    "accuracy_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "related-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[3.45638663]\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "False\n",
      "9 + 60 = 1\n",
      "------------\n",
      "Error:[4.16930229]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 0 0 1 1]\n",
      "False\n",
      "110 + 37 = 255\n",
      "------------\n",
      "Error:[4.31669137]\n",
      "Pred:[1 1 0 1 1 0 1 1]\n",
      "True:[1 0 0 0 0 0 0 0]\n",
      "False\n",
      "83 + 45 = 219\n",
      "------------\n",
      "Error:[4.07523654]\n",
      "Pred:[1 1 1 1 1 1 0 0]\n",
      "True:[1 0 1 0 0 0 0 0]\n",
      "False\n",
      "120 + 40 = 252\n",
      "------------\n",
      "Error:[3.79322633]\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[0 0 1 0 1 0 0 0]\n",
      "False\n",
      "3 + 37 = 72\n",
      "------------\n",
      "Error:[4.02253884]\n",
      "Pred:[0 1 1 0 1 0 1 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "False\n",
      "112 + 17 = 107\n",
      "------------\n",
      "Error:[4.13504327]\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "False\n",
      "44 + 38 = 108\n",
      "------------\n",
      "Error:[4.0695968]\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[1 0 0 0 1 0 1 1]\n",
      "False\n",
      "84 + 55 = 108\n",
      "------------\n",
      "Error:[4.01870086]\n",
      "Pred:[1 1 1 1 1 1 0 1]\n",
      "True:[0 0 0 1 0 0 0 1]\n",
      "False\n",
      "17 + 0 = 253\n",
      "------------\n",
      "Error:[3.8042653]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "False\n",
      "7 + 122 = 0\n",
      "------------\n",
      "Error:[3.63389116]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 1 1]\n",
      "False\n",
      "28 + 35 = 255\n",
      "------------\n",
      "Error:[3.75889272]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "False\n",
      "11 + 108 = 255\n",
      "------------\n",
      "Error:[3.89161112]\n",
      "Pred:[1 1 1 1 1 0 1 0]\n",
      "True:[1 0 1 1 1 0 1 1]\n",
      "False\n",
      "122 + 65 = 250\n",
      "------------\n",
      "Error:[4.17753372]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 1 1 1 0 0 1 1]\n",
      "False\n",
      "116 + 127 = 0\n",
      "------------\n",
      "Error:[3.96075278]\n",
      "Pred:[1 1 0 1 1 1 0 0]\n",
      "True:[1 1 0 1 1 1 1 1]\n",
      "False\n",
      "113 + 110 = 220\n",
      "------------\n",
      "Error:[3.99234598]\n",
      "Pred:[1 1 0 1 1 0 1 0]\n",
      "True:[1 0 1 1 0 0 1 1]\n",
      "False\n",
      "78 + 101 = 218\n",
      "------------\n",
      "Error:[4.01364303]\n",
      "Pred:[1 0 1 1 0 0 1 0]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "False\n",
      "59 + 89 = 178\n",
      "------------\n",
      "Error:[3.77635868]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 0 0 0]\n",
      "False\n",
      "108 + 12 = 255\n",
      "------------\n",
      "Error:[4.0399508]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "False\n",
      "80 + 57 = 0\n",
      "------------\n",
      "Error:[3.90807214]\n",
      "Pred:[1 1 0 1 1 0 1 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "False\n",
      "35 + 109 = 218\n",
      "------------\n",
      "Error:[3.91366595]\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[1 0 1 0 0 0 0 0]\n",
      "False\n",
      "116 + 44 = 72\n",
      "------------\n",
      "Error:[3.98315624]\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "False\n",
      "21 + 97 = 99\n",
      "------------\n",
      "Error:[3.62306596]\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "False\n",
      "64 + 33 = 99\n",
      "------------\n",
      "Error:[3.93007143]\n",
      "Pred:[1 1 1 1 1 0 1 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "False\n",
      "32 + 73 = 251\n",
      "------------\n",
      "Error:[3.73586568]\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 1 0]\n",
      "False\n",
      "19 + 43 = 127\n",
      "------------\n",
      "Error:[3.65154804]\n",
      "Pred:[1 1 0 1 1 0 1 0]\n",
      "True:[1 1 0 1 1 1 1 0]\n",
      "False\n",
      "122 + 100 = 218\n",
      "------------\n",
      "Error:[3.93219845]\n",
      "Pred:[1 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 1 1 1 1 0]\n",
      "False\n",
      "100 + 122 = 128\n",
      "------------\n",
      "Error:[4.26281629]\n",
      "Pred:[1 0 1 0 1 0 0 0]\n",
      "True:[1 1 0 1 0 1 0 1]\n",
      "False\n",
      "126 + 87 = 168\n",
      "------------\n",
      "Error:[3.74387203]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "False\n",
      "105 + 0 = 0\n",
      "------------\n",
      "Error:[4.1344748]\n",
      "Pred:[1 1 0 0 1 1 0 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "False\n",
      "42 + 102 = 204\n",
      "------------\n",
      "Error:[3.72191702]\n",
      "Pred:[1 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "False\n",
      "4 + 73 = 223\n",
      "------------\n",
      "Error:[4.18324852]\n",
      "Pred:[0 1 1 1 0 1 0 0]\n",
      "True:[1 0 0 1 1 0 0 0]\n",
      "False\n",
      "90 + 62 = 116\n",
      "------------\n",
      "Error:[4.01695734]\n",
      "Pred:[1 0 0 1 1 1 1 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "False\n",
      "71 + 73 = 158\n",
      "------------\n",
      "Error:[3.74758594]\n",
      "Pred:[0 0 1 1 0 0 1 1]\n",
      "True:[0 1 0 0 0 1 1 1]\n",
      "False\n",
      "30 + 41 = 51\n",
      "------------\n",
      "Error:[3.65735218]\n",
      "Pred:[1 1 1 1 0 1 1 0]\n",
      "True:[1 0 1 1 0 1 1 0]\n",
      "False\n",
      "58 + 124 = 246\n",
      "------------\n",
      "Error:[3.35048888]\n",
      "Pred:[1 0 0 1 1 0 0 1]\n",
      "True:[1 0 0 1 0 0 0 1]\n",
      "False\n",
      "76 + 69 = 153\n",
      "------------\n",
      "Error:[4.15341654]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 1 0 0 1 0 0]\n",
      "False\n",
      "73 + 91 = 255\n",
      "------------\n",
      "Error:[3.21976918]\n",
      "Pred:[0 0 1 1 1 1 0 1]\n",
      "True:[0 0 1 1 1 1 0 1]\n",
      "True\n",
      "52 + 9 = 61\n",
      "------------\n",
      "Error:[3.42513654]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "False\n",
      "90 + 12 = 0\n",
      "------------\n",
      "Error:[3.42773469]\n",
      "Pred:[1 1 0 1 1 1 0 1]\n",
      "True:[1 0 0 1 1 1 0 1]\n",
      "False\n",
      "33 + 124 = 221\n",
      "------------\n",
      "Error:[3.5852713]\n",
      "Pred:[0 0 0 0 1 0 0 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "False\n",
      "71 + 11 = 8\n",
      "------------\n",
      "Error:[3.77436327]\n",
      "Pred:[1 0 1 1 0 0 1 1]\n",
      "True:[1 1 0 0 1 0 1 1]\n",
      "False\n",
      "110 + 93 = 179\n",
      "------------\n",
      "Error:[3.31828892]\n",
      "Pred:[0 1 0 1 0 1 0 1]\n",
      "True:[0 1 1 0 0 1 0 1]\n",
      "False\n",
      "59 + 42 = 85\n",
      "------------\n",
      "Error:[3.26929669]\n",
      "Pred:[0 0 1 0 0 1 1 0]\n",
      "True:[0 1 0 0 0 1 1 0]\n",
      "False\n",
      "30 + 40 = 38\n",
      "------------\n",
      "Error:[2.22594462]\n",
      "Pred:[1 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "True\n",
      "104 + 65 = 169\n",
      "------------\n",
      "Error:[2.43239777]\n",
      "Pred:[0 1 1 0 1 0 1 1]\n",
      "True:[0 1 1 0 1 0 1 1]\n",
      "True\n",
      "72 + 35 = 107\n",
      "------------\n",
      "Error:[3.00358561]\n",
      "Pred:[0 1 1 0 0 1 0 0]\n",
      "True:[0 1 1 0 1 0 0 0]\n",
      "False\n",
      "35 + 69 = 100\n",
      "------------\n",
      "Error:[2.40474093]\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "False\n",
      "52 + 57 = 77\n",
      "------------\n",
      "Error:[2.93084871]\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 1 0 0 1 1 0 0]\n",
      "False\n",
      "102 + 102 = 136\n",
      "------------\n",
      "Error:[2.04096876]\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "True\n",
      "42 + 35 = 77\n",
      "------------\n",
      "Error:[2.53352328]\n",
      "Pred:[1 0 1 0 0 0 1 0]\n",
      "True:[1 1 0 0 0 0 1 0]\n",
      "False\n",
      "81 + 113 = 162\n",
      "------------\n",
      "Error:[2.40441322]\n",
      "Pred:[1 0 1 0 0 1 0 0]\n",
      "True:[1 0 1 0 0 1 0 0]\n",
      "True\n",
      "108 + 56 = 164\n",
      "------------\n",
      "Error:[2.89876495]\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 0 0 1 0 0 1 1]\n",
      "False\n",
      "117 + 30 = 131\n",
      "------------\n",
      "Error:[1.5627634]\n",
      "Pred:[1 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "True\n",
      "97 + 72 = 169\n",
      "------------\n",
      "Error:[2.50959224]\n",
      "Pred:[0 1 1 1 1 1 0 0]\n",
      "True:[0 1 1 1 1 0 0 0]\n",
      "False\n",
      "27 + 93 = 124\n",
      "------------\n",
      "Error:[1.87382863]\n",
      "Pred:[0 1 1 0 0 0 1 0]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "True\n",
      "21 + 77 = 98\n",
      "------------\n",
      "Error:[2.21893611]\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 1 1]\n",
      "True\n",
      "32 + 47 = 79\n",
      "------------\n",
      "Error:[1.78808575]\n",
      "Pred:[1 0 0 1 0 1 1 0]\n",
      "True:[1 0 0 1 0 1 1 0]\n",
      "True\n",
      "44 + 106 = 150\n",
      "------------\n",
      "Error:[1.16841419]\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "True\n",
      "32 + 104 = 136\n",
      "------------\n",
      "Error:[1.09045944]\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "True\n",
      "74 + 34 = 108\n",
      "------------\n",
      "Error:[0.57691441]\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "True\n",
      "81 + 0 = 81\n",
      "------------\n",
      "Error:[1.47368785]\n",
      "Pred:[0 1 0 1 0 1 1 1]\n",
      "True:[0 1 0 1 0 1 1 1]\n",
      "True\n",
      "79 + 8 = 87\n",
      "------------\n",
      "Error:[0.70507817]\n",
      "Pred:[0 0 0 1 0 0 0 1]\n",
      "True:[0 0 0 1 0 0 0 1]\n",
      "True\n",
      "12 + 5 = 17\n",
      "------------\n",
      "Error:[1.10900362]\n",
      "Pred:[1 0 1 1 0 1 0 0]\n",
      "True:[1 0 1 1 0 1 0 0]\n",
      "True\n",
      "65 + 115 = 180\n",
      "------------\n",
      "Error:[2.85525094]\n",
      "Pred:[0 1 1 0 0 1 1 1]\n",
      "True:[0 1 0 1 1 1 1 1]\n",
      "False\n",
      "3 + 92 = 103\n",
      "------------\n",
      "Error:[0.75100965]\n",
      "Pred:[0 0 1 1 1 1 0 0]\n",
      "True:[0 0 1 1 1 1 0 0]\n",
      "True\n",
      "49 + 11 = 60\n",
      "------------\n",
      "Error:[2.15980704]\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 0 0 1 1 1 1]\n",
      "False\n",
      "69 + 74 = 155\n",
      "------------\n",
      "Error:[1.10015853]\n",
      "Pred:[1 1 0 0 1 1 0 0]\n",
      "True:[1 1 0 0 1 1 0 0]\n",
      "True\n",
      "121 + 83 = 204\n",
      "------------\n",
      "Error:[0.671224]\n",
      "Pred:[0 1 0 1 1 1 0 0]\n",
      "True:[0 1 0 1 1 1 0 0]\n",
      "True\n",
      "81 + 11 = 92\n",
      "------------\n",
      "Error:[0.80628077]\n",
      "Pred:[1 0 0 0 1 1 0 1]\n",
      "True:[1 0 0 0 1 1 0 1]\n",
      "True\n",
      "67 + 74 = 141\n",
      "------------\n",
      "Error:[1.42589952]\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "True\n",
      "4 + 125 = 129\n",
      "------------\n",
      "Error:[0.56502609]\n",
      "Pred:[1 0 1 1 0 1 0 1]\n",
      "True:[1 0 1 1 0 1 0 1]\n",
      "True\n",
      "85 + 96 = 181\n",
      "------------\n",
      "Error:[0.48612654]\n",
      "Pred:[0 0 1 1 1 1 0 1]\n",
      "True:[0 0 1 1 1 1 0 1]\n",
      "True\n",
      "17 + 44 = 61\n",
      "------------\n",
      "Error:[0.71308727]\n",
      "Pred:[1 0 0 1 0 1 1 1]\n",
      "True:[1 0 0 1 0 1 1 1]\n",
      "True\n",
      "34 + 117 = 151\n",
      "------------\n",
      "Error:[0.81753954]\n",
      "Pred:[1 0 0 1 0 1 1 1]\n",
      "True:[1 0 0 1 0 1 1 1]\n",
      "True\n",
      "115 + 36 = 151\n",
      "------------\n",
      "Error:[0.6594703]\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "True\n",
      "80 + 28 = 108\n",
      "------------\n",
      "Error:[0.6592707]\n",
      "Pred:[1 0 0 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 1 1 1]\n",
      "True\n",
      "126 + 33 = 159\n",
      "------------\n",
      "Error:[0.53628036]\n",
      "Pred:[1 0 1 0 1 1 1 0]\n",
      "True:[1 0 1 0 1 1 1 0]\n",
      "True\n",
      "105 + 69 = 174\n",
      "------------\n",
      "Error:[0.8308726]\n",
      "Pred:[1 0 0 0 1 1 0 1]\n",
      "True:[1 0 0 0 1 1 0 1]\n",
      "True\n",
      "27 + 114 = 141\n",
      "------------\n",
      "Error:[0.38294208]\n",
      "Pred:[1 0 1 1 0 1 1 0]\n",
      "True:[1 0 1 1 0 1 1 0]\n",
      "True\n",
      "117 + 65 = 182\n",
      "------------\n",
      "Error:[0.47477457]\n",
      "Pred:[0 0 1 1 1 0 0 0]\n",
      "True:[0 0 1 1 1 0 0 0]\n",
      "True\n",
      "39 + 17 = 56\n",
      "------------\n",
      "Error:[0.2288582]\n",
      "Pred:[0 0 0 1 0 1 0 1]\n",
      "True:[0 0 0 1 0 1 0 1]\n",
      "True\n",
      "4 + 17 = 21\n",
      "------------\n",
      "Error:[0.27901518]\n",
      "Pred:[0 0 0 0 1 1 1 0]\n",
      "True:[0 0 0 0 1 1 1 0]\n",
      "True\n",
      "12 + 2 = 14\n",
      "------------\n",
      "Error:[0.63591283]\n",
      "Pred:[0 0 1 0 1 1 0 1]\n",
      "True:[0 0 1 0 1 1 0 1]\n",
      "True\n",
      "31 + 14 = 45\n",
      "------------\n",
      "Error:[0.29056341]\n",
      "Pred:[0 1 0 1 1 1 0 1]\n",
      "True:[0 1 0 1 1 1 0 1]\n",
      "True\n",
      "24 + 69 = 93\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[0.7200904]\n",
      "Pred:[1 0 1 0 1 0 0 0]\n",
      "True:[1 0 1 0 1 0 0 0]\n",
      "True\n",
      "123 + 45 = 168\n",
      "------------\n",
      "Error:[0.54544162]\n",
      "Pred:[0 1 0 0 0 0 1 0]\n",
      "True:[0 1 0 0 0 0 1 0]\n",
      "True\n",
      "43 + 23 = 66\n",
      "------------\n",
      "Error:[0.59992038]\n",
      "Pred:[0 1 1 0 1 0 0 0]\n",
      "True:[0 1 1 0 1 0 0 0]\n",
      "True\n",
      "30 + 74 = 104\n",
      "------------\n",
      "Error:[0.67717711]\n",
      "Pred:[1 0 0 0 0 0 0 0]\n",
      "True:[1 0 0 0 0 0 0 0]\n",
      "True\n",
      "76 + 52 = 128\n",
      "------------\n",
      "Error:[0.46859902]\n",
      "Pred:[0 1 0 0 0 1 1 0]\n",
      "True:[0 1 0 0 0 1 1 0]\n",
      "True\n",
      "9 + 61 = 70\n",
      "------------\n",
      "Error:[0.21595037]\n",
      "Pred:[0 0 0 0 1 1 1 0]\n",
      "True:[0 0 0 0 1 1 1 0]\n",
      "True\n",
      "11 + 3 = 14\n",
      "------------\n",
      "Error:[0.54648787]\n",
      "Pred:[1 1 1 0 0 1 1 0]\n",
      "True:[1 1 1 0 0 1 1 0]\n",
      "True\n",
      "120 + 110 = 230\n",
      "------------\n",
      "Error:[0.43902376]\n",
      "Pred:[0 0 0 1 1 0 0 1]\n",
      "True:[0 0 0 1 1 0 0 1]\n",
      "True\n",
      "19 + 6 = 25\n",
      "------------\n",
      "Error:[0.48259762]\n",
      "Pred:[0 1 1 1 0 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "True\n",
      "105 + 14 = 119\n",
      "------------\n",
      "Error:[0.5309755]\n",
      "Pred:[0 1 0 1 1 0 0 1]\n",
      "True:[0 1 0 1 1 0 0 1]\n",
      "True\n",
      "29 + 60 = 89\n",
      "------------\n",
      "Error:[0.52112049]\n",
      "Pred:[1 0 1 0 1 0 1 1]\n",
      "True:[1 0 1 0 1 0 1 1]\n",
      "True\n",
      "71 + 100 = 171\n",
      "------------\n",
      "Error:[0.30912111]\n",
      "Pred:[0 1 1 0 0 0 1 0]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "True\n",
      "81 + 17 = 98\n",
      "------------\n",
      "Error:[0.30263493]\n",
      "Pred:[1 0 1 0 1 0 1 0]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "True\n",
      "106 + 64 = 170\n",
      "------------\n",
      "Error:[0.45662863]\n",
      "Pred:[1 1 1 0 0 1 0 1]\n",
      "True:[1 1 1 0 0 1 0 1]\n",
      "True\n",
      "104 + 125 = 229\n",
      "------------\n",
      "Error:[0.53493863]\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "True\n",
      "35 + 46 = 81\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# training!!\n",
    "\n",
    "for j in range(10000): # 10000번 돌린다\n",
    "    \n",
    "    # a, b를 생성하고 두 값을 더한 c를 계산한다.\n",
    "    # 복잡성을 줄이기 위해(toy code)\n",
    "    # a, b는 largest_number 의 절반 - 1 크기의 랜덤 정수값이다. 따라서 a + b < largest_number\n",
    "\n",
    "    a_int = np.random.randint(largest_number / 2)\n",
    "    a = int2binary[a_int]\n",
    "\n",
    "    b_int = np.random.randint(largest_number / 2)\n",
    "    b = int2binary[b_int]\n",
    "\n",
    "    # 입력값 a, b를 임의 생성했으니  정답인 c도 확보해두자(=label. 따라서 우리는 supervised learning 중이다)\n",
    "    c_int = a_int + b_int\n",
    "    c = int2binary[c_int]\n",
    "\n",
    "    # c에는 정답이 들어있고, predict_binary에는 우리 네트워크가 예측한 값을 넣어두자.\n",
    "    d = np.zeros_like(c)\n",
    "\n",
    "    overallError = 0  # 에러값을 저장할 공간\n",
    "\n",
    "    # 각 time step마다 output_layer의 미분값과 hidden_layer의 값을 추적할 리스트이다.\n",
    "    output_layer_deltas = list()\n",
    "    hidden_layer_values = list()\n",
    "\n",
    "    # output_layer_deltas 에는 생성한 값을 넣으면 되지만\n",
    "    # hidden_layer_values 처음에는 이전 hidden이 없으니 0으로 한다\n",
    "    hidden_layer_values.append(np.zeros(hidden_node_num))\n",
    "\n",
    "    # forward propagation 부터\n",
    "    #---------------------------------------------------------------\n",
    "    # 여기서부터 각 자리수별로 NN을 돌린다\n",
    "    #---------------------------------------------------------------\n",
    "    # 낮은 자리수부터 각 자리수별로 for 문을 돌면서 수행한다.\n",
    "    for position in range(binary_dim):\n",
    "\n",
    "        # 입력값과 정답(=label)을 각각 X와 y에 써넣자\n",
    "        X = np.array([[a[binary_dim - position-1], b[binary_dim - position-1]]])\n",
    "        y = np.array([[c[binary_dim - position-1]]]).T\n",
    "        \n",
    "     \n",
    "        # hidden layer 연산부 (input ~+ prev_hidden) 이 부분이 RNN의 매우 중요한 부분이다\n",
    "        # hidden layer 연산이다. input X와 weight_input_hidden(=W0) 을 곱해주고,\n",
    "        # 이전의(= -1 = 가장 마지막의) hidden layer 값과 Wweight_hidden_hidden(=Wh)를 곱해준다.\n",
    "        # 그리고 두 값을 더한뒤 sigmoid 먹여준다. 더해준다는 것이 중요하다\n",
    "        hidden_layer = sigmoid(np.dot(X, w0) + np.dot(hidden_layer_values[-1], wh))\n",
    "\n",
    "        # output layer (new binary representation)\n",
    "        # output layer는 이렇게 나온 hidden_layer 값과 weight_hidden_output(= W1) 값을 곱해준뒤 sigmoid 해준다\n",
    "        output_layer = sigmoid(np.dot(hidden_layer, w1))\n",
    "\n",
    "        # 정답과 예측값을 비교해서 loss를 계산해보자\n",
    "        # 일치하면 0, 틀리면 절대값이 1일 것이다. \n",
    "        output_layer_error = y - output_layer  \n",
    "\n",
    "        # 우선 sigmoid에 대한 미분값만을 계산하고 저장하자. \n",
    "        output_layer_deltas.append((output_layer_error) * sigmoid_output_to_derivative(output_layer))\n",
    "\n",
    "        # 에러율 저장\n",
    "        overallError += np.abs(output_layer_error[0])\n",
    "\n",
    "        # 예측값 저장하기. sigmoid 결과값이니 \n",
    "        d[binary_dim - position - 1] = np.round(output_layer[0][0])\n",
    "\n",
    "        '''\n",
    "        if (j == 9999):\n",
    "            print (\"hidden_layer.shape: \", hidden_layer.shape)\n",
    "            print (\"output_layer_error.shape: \", output_layer_error.shape)\n",
    "            print (\"output_layer.shape: \", output_layer.shape)\n",
    "            print (\"output_layer: \", output_layer)\n",
    "            print (\"-------------------------------\")\n",
    "        '''\n",
    "        \n",
    "        # 계산한 hidden_layer는 다음 자리수 계산을 위해 보관해두자\n",
    "        hidden_layer_values.append(copy.deepcopy(hidden_layer))\n",
    "\n",
    "        # 루프를 다 돌면 모든 자리수에 대한 forward propagation 완료된 것\n",
    "\n",
    "    # 미분을 위해서는 그 다음 상위 hidden_layer에서의 미분값이 필요한데 없으므로 0을 채워놓음\n",
    "    future_hidden_layer_delta = np.zeros(hidden_node_num)\n",
    "    \n",
    "    # display 용도\n",
    "    if (j % 100 == 0):\n",
    "        overallError_history.append(overallError[0])\n",
    "        \n",
    "    # 이제 backward propagation\n",
    "    \n",
    "    for position in range(binary_dim):\n",
    "\n",
    "        ##################################################################################\n",
    "        #일단 보관해뒀던 값들을 다 꺼낸다\n",
    "\n",
    "        X = np.array([[a[position], b[position]]])  # 이번엔 맨 왼쪽의 가장 높은 자리수부터 계산해야겠지?\n",
    "        hidden_layer = hidden_layer_values[-position - 1]  # 가장 나중 time step의 hidden layer의 값을 꺼내고\n",
    "        prev_hidden_layer = hidden_layer_values[-position - 2] # 그 하나전의 prev hidden layer의 값도 꺼낸다\n",
    "\n",
    "        # error at output layer\n",
    "        # 현재 자릿수의 output layer의 미분한 값값\n",
    "        output_layer_delta = output_layer_deltas[-position - 1]\n",
    "\n",
    "        ##################################################################################\n",
    "        # error at hidden layer\n",
    "        # 이제 현재 자리수의(=현재 time step)의 hidden layer의 미분값을 계산한다\n",
    "\n",
    "        # 다음 layer에서 내려오는 값과 weight_hidden_(=Wh) 값을 곱하고\n",
    "        # output layer의 미분값과 synapse_1(=W1)값을 곱한 값을 다시 layer_1의 미분값과 곱해준다.\n",
    "        # 이부분은 어렵다. 차근히 봐야겠다\n",
    "        hidden_layer_delta = (future_hidden_layer_delta.dot(wh.T) \\\n",
    "                              + output_layer_delta.dot(w1.T)) * sigmoid_output_to_derivative(hidden_layer)\n",
    "\n",
    "        # let's update all our weights so we can try again\n",
    "        # 이제 weight 값들을 업데이트 해줄 시간이다.\n",
    "        w1_update += np.atleast_2d(hidden_layer).T.dot(output_layer_delta)\n",
    "        wh_update += np.atleast_2d(prev_hidden_layer).T.dot(hidden_layer_delta)\n",
    "        w0_update += X.T.dot(hidden_layer_delta)\n",
    "\n",
    "        future_hidden_layer_delta = hidden_layer_delta\n",
    "\n",
    "    # 모두 다 업데이트 해준다. alpha 라는 learning_rate에 맞춰서 update\n",
    "    # 이렇게 모든 자리수의 backpropagation이 끝난뒤에 update 하는 것이다.\n",
    "\n",
    "    w1 += w1_update * alpha\n",
    "    w0 += w0_update * alpha\n",
    "    wh += wh_update * alpha\n",
    "\n",
    "    # 그리고 다시 초기화\n",
    "    w1_update *= 0\n",
    "    w0_update *= 0\n",
    "    wh_update *= 0\n",
    "\n",
    "    ##################################################################################\n",
    "    #  진행사항 저장\n",
    "    #  참인지 저깃인지를 계속 체크\n",
    "    check = np.equal(d,c)\n",
    "#     print(\"check:\", np.sum(check), binary_dim)\n",
    "    if (np.sum(check) == binary_dim):  # 같은 것 개수가 8개면 참이다\n",
    "        accuracy_count += 1\n",
    "    \n",
    "    # 100번마다 accuracy에서 값을 찾는다. \n",
    "    if (j % 100 == 0):\n",
    "#         print(\"accuracy_count\", accuracy_count)\n",
    "        accuracy_history.append(accuracy_count)\n",
    "        accuracy_count = 0\n",
    "        \n",
    "    ##################################################################################\n",
    "    #  print out progress\n",
    "    #  100번마다 중간 진행 사항을 update 하자\n",
    "    \n",
    "    if (j % 100 == 0):\n",
    "        print (\"Error:\" + str(overallError))\n",
    "        print (\"Pred:\" + str(d))  # 예측값\n",
    "        print (\"True:\" + str(c))  # 실제값\n",
    "\n",
    "        final_check = np.equal(d,c)\n",
    "        print (np.sum(final_check) == binary_dim)\n",
    "\n",
    "        out = 0\n",
    "\n",
    "        for index, x in enumerate(reversed(d)):\n",
    "            out += x * pow(2, index)\n",
    "        print (str(a_int) + \" + \" + str(b_int) + \" = \" + str(out))\n",
    "        print (\"------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "large-letter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0\n",
      "[[-3.59519530e-01  2.33958993e+00 -3.20338283e-01 -1.23380148e+00\n",
      "   8.23329522e-02 -1.45748081e-01 -6.45250995e+00  4.49331950e+00\n",
      "   3.26692732e+00 -1.20738586e+00  1.15429892e+00 -2.40883011e-03\n",
      "  -1.33888050e+00  8.52716118e-01 -5.14494757e+00 -1.06330714e+00]\n",
      " [-2.68069543e+00  1.89873078e+00  1.87995848e+00  1.36240935e+00\n",
      "   1.49624674e+00  1.13808369e+00  5.07559597e+00  3.84828275e+00\n",
      "  -1.60133079e+00 -6.85907484e-01 -2.99388346e+00  3.72908685e+00\n",
      "  -2.03880654e+00 -1.85161240e+00 -5.18525010e+00  1.15066749e+00]]\n",
      "w1\n",
      "[[ 2.03071179]\n",
      " [-0.66162995]\n",
      " [-2.46164979]\n",
      " [-2.14926531]\n",
      " [-1.316041  ]\n",
      " [-1.26025501]\n",
      " [ 7.9664284 ]\n",
      " [ 6.39502015]\n",
      " [-1.38569981]\n",
      " [-0.28722474]\n",
      " [ 1.84409219]\n",
      " [-3.92645053]\n",
      " [ 1.06560186]\n",
      " [ 0.96352614]\n",
      " [-8.58559082]\n",
      " [-2.02362742]]\n",
      "wh\n",
      "[[ 0.03181292 -1.57610668  0.02068267  0.15980357  0.51340376 -0.54424461\n",
      "  -2.37928976  0.16707457 -0.10072398 -0.07600941  0.09385251 -1.18412748\n",
      "   0.50169375 -0.43218294  1.58562712 -0.54266278]\n",
      " [-0.65419518  0.22925434  0.76290475 -0.83081858  0.67274591 -0.66477158\n",
      "   2.73452205 -2.35568549  1.6093527  -0.18013518 -0.46082073 -0.47483798\n",
      "  -0.79219389 -1.4475196  -1.74391352 -0.67660372]\n",
      " [-0.29566957 -0.14515312 -0.96830975  0.24622941 -0.00588823 -0.33812007\n",
      "   0.93265849 -1.61233371  0.68600202  0.3934923  -1.00488647  0.20010635\n",
      "  -0.80244805 -0.10380378 -0.60413093 -0.78597967]\n",
      " [ 0.15943183 -1.34861031  0.58052277 -0.79993508  0.17865188 -0.41207984\n",
      "  -0.6390113   1.13361444 -0.49446918  0.21561124 -0.03540312  0.06256037\n",
      "  -0.13271672  0.96838917  0.74859709  0.73047402]\n",
      " [ 0.34869417 -0.2431448   0.61619874 -0.27138817  0.70766359  0.29838068\n",
      "   1.66712502 -0.93158872  1.02359046 -0.46577053  0.06179862  0.52136402\n",
      "  -0.4659724  -0.43674099 -1.41580205 -0.45366324]\n",
      " [ 0.12436744 -0.13425276  0.19222372 -0.050556   -0.55385554 -0.13988762\n",
      "   0.50394111 -0.8090668   0.5253116  -0.12963408 -0.28035719 -0.08840669\n",
      "   0.52029958 -0.84576588 -0.71729001  0.77746124]\n",
      " [ 1.18032983 -0.95224643 -1.19507943  1.05081765  0.00652372  0.96173471\n",
      "  -2.41926577  1.63630089 -0.90617352  0.58054031 -0.27354501 -0.66075364\n",
      "   1.35042705  0.68751897  1.68421467 -0.77307115]\n",
      " [ 1.11105834 -1.04905073  0.04878561  0.8126651   0.20047739  0.40857149\n",
      "  -1.25233084  0.87260283  0.10607076  0.08100951 -0.0704001  -1.09310938\n",
      "   0.68790574 -0.59887111  0.55503872 -0.39693485]\n",
      " [-0.31040234  0.92768181  0.3978287  -0.9246784  -0.7558818   0.66933396\n",
      "   1.86431354 -2.20293814  1.35168391 -0.35416802 -0.68689088  0.10906915\n",
      "   0.32033828 -1.288814   -1.49078566 -0.49590446]\n",
      " [-0.28218851 -0.26628482  0.34265901  0.04403331 -1.10214692 -0.48419089\n",
      "  -2.38505233  0.87989146 -0.5262599   0.7186787  -0.1440471  -1.18837266\n",
      "   0.02346226 -0.48749235  1.53628314 -0.12545696]\n",
      " [ 0.4340515  -0.62742089  0.84567214 -0.31368354 -0.1729571  -0.21270624\n",
      "  -2.2271734   1.24506826 -0.76829302  0.07778248  0.46123087 -0.2290079\n",
      "   1.55825931  0.98848587  0.63211562  0.84318512]\n",
      " [-0.48095922  1.25608632  0.2525628  -0.72019784  0.82385304  0.31849202\n",
      "   0.89306824 -1.70791041  0.57434782 -1.11819422 -1.16787109 -0.11624765\n",
      "  -0.56187563 -0.43328798 -1.06240294  0.09348005]\n",
      " [ 1.10375198 -1.84870891 -0.23875625 -0.52964414  0.09403066 -0.03487203\n",
      "  -1.50815526  0.7442655  -1.09837206  0.3297744   0.03361467  0.13758756\n",
      "   1.65449918  0.83370811  1.51217242 -0.79356488]\n",
      " [ 0.59035046 -1.14848827  0.69580869 -0.20384397 -1.07977277 -0.74877129\n",
      "  -2.33023849  1.88741274 -0.12612334  1.13006919 -0.06686066 -0.64959205\n",
      "   0.46163558  0.45794248  2.02077812  0.947547  ]\n",
      " [-0.69301034  1.09375177 -0.44975003  0.66410715  1.09781567  0.80014258\n",
      "   0.02553356  1.21997398  0.00698922  0.14474051 -0.01058037 -0.71710903\n",
      "  -0.52475367 -1.20956399  0.29715381 -0.30589397]\n",
      " [ 0.11550181 -0.27654194 -0.3428275  -0.51735203  0.44155736 -0.57633273\n",
      "  -1.2621032  -0.05282625 -0.88338172  0.90145372  0.91711727  0.58807147\n",
      "   1.41716245  0.74379707  0.94776698 -0.74644035]]\n"
     ]
    }
   ],
   "source": [
    "x_range = range(100)\n",
    "plt.plot(x_range, overallError_history, 'r-')\n",
    "plt.ylabel('overallError')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(x_range, accuracy_history, 'b-')\n",
    "plt.ylabel('accuracy_history')\n",
    "plt.show()\n",
    "\n",
    "print(\"w0\")\n",
    "print(w0)\n",
    "print(\"w1\")\n",
    "print(w1)\n",
    "print(\"wh\")\n",
    "print(wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-westminster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
